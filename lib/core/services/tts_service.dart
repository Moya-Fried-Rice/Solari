import 'dart:io';
import 'dart:typed_data';
import 'package:flutter/material.dart';
import 'package:flutter/services.dart';
import 'package:sherpa_onnx/sherpa_onnx.dart' as sherpa_onnx;
import 'package:path_provider/path_provider.dart';
import 'package:path/path.dart' as p;
import 'ble_service.dart';

/// Advanced TTS service using Sherpa ONNX for high-quality neural text-to-speech
/// Provides offline, neural network-based speech synthesis for Solari smart glasses
class TtsService {
  static final TtsService _instance = TtsService._internal();
  factory TtsService() => _instance;
  TtsService._internal();

  final BleService _bleService = BleService();
  sherpa_onnx.OfflineTts? _sherpaEngine;
  
  bool _isInitialized = false;
  bool _isSpeaking = false;
  double _speechSpeed = 0.8;
  bool _useBleTransmission = true; // Prefer BLE over local playback

  /// Initialize the Sherpa ONNX TTS engine
  Future<void> initialize() async {
    if (_isInitialized) return;

    try {
      debugPrint('Initializing Sherpa ONNX TTS engine...');
      
      // Initialize Sherpa ONNX bindings
      sherpa_onnx.initBindings();
      
      // Create the offline TTS engine
      _sherpaEngine = await _createOfflineTts();
      
      _isInitialized = true;
      debugPrint('Sherpa ONNX TTS service initialized successfully');
    } catch (e) {
      debugPrint('Error initializing Sherpa ONNX TTS service: $e');
      throw Exception('Failed to initialize Sherpa ONNX TTS service: $e');
    }
  }

  /// Get current speaking status
  bool get isSpeaking => _isSpeaking;

  /// Get current speech speed
  double get speechSpeed => _speechSpeed;

  /// Set speech speed (0.5x to 2.0x)
  void setSpeechSpeed(double speed) {
    _speechSpeed = speed.clamp(0.5, 2.0);
    debugPrint('Speech speed set to: $_speechSpeed');
  }

  /// Enable or disable BLE transmission (defaults to true for smart glasses)
  void setBleTransmission(bool enabled) {
    _useBleTransmission = enabled;
    debugPrint('BLE transmission ${enabled ? "enabled" : "disabled"} - will use ${enabled ? "smart glasses" : "local playback"}');
  }

  /// Check if BLE transmission is enabled and available
  bool get canUseBle => _useBleTransmission && _bleService.isReady;

  /// Generate speech using Sherpa ONNX and play it
  Future<void> speakText(String text, {
    Function()? onStart,
    Function()? onComplete,
    Function(String error)? onError,
  }) async {
    if (!_isInitialized) {
      await initialize();
    }

    if (_sherpaEngine == null) {
      onError?.call('Sherpa ONNX engine not initialized');
      return;
    }

    if (_isSpeaking) {
      debugPrint('Already speaking, stopping current speech');
      await stopSpeaking();
    }

    try {
      _isSpeaking = true;
      onStart?.call();

      // Limit text length for performance
      String processedText = text;
      const int maxTextLength = 500;
      
      if (text.length > maxTextLength) {
        processedText = text.substring(0, maxTextLength);
        debugPrint('Text truncated from ${text.length} to $maxTextLength characters');
      }

      debugPrint('Generating neural speech for: "$processedText" at ${_speechSpeed}x speed');
      
      final stopwatch = Stopwatch();
      stopwatch.start();
      
      // Generate speech using Sherpa ONNX
      final audio = _sherpaEngine!.generate(
        text: processedText, 
        sid: 0, 
        speed: _speechSpeed
      );
      
      stopwatch.stop();
      final elapsed = stopwatch.elapsed.inMilliseconds.toDouble();
      final duration = audio.samples.length.toDouble() / audio.sampleRate.toDouble();
      
      debugPrint('‚úÖ Neural speech generated successfully!');
      debugPrint('   Sample Rate: ${audio.sampleRate}Hz');
      debugPrint('   Samples: ${audio.samples.length}');
      debugPrint('   Duration: ${duration.toStringAsPrecision(2)}s');
      debugPrint('   Generation time: ${(elapsed / 1000).toStringAsPrecision(2)}s');

      // Send audio samples directly to smart glasses via BLE
      if (canUseBle) {
        debugPrint('üì° Sending ${audio.sampleRate}Hz audio to smart glasses via BLE...');
        
        final audioBytes = _convertSamplesToBytes(audio.samples, audio.sampleRate);
        
        await _bleService.sendAudioData(
          audioBytes,
          onStart: () => debugPrint('üéµ Starting BLE audio transmission'),
          onProgress: (sent, total) {
            final progress = (sent / total * 100).toStringAsFixed(1);
            debugPrint('üìä BLE progress: $progress% ($sent/$total bytes)');
          },
          onComplete: () {
            debugPrint('‚úÖ Audio transmitted to smart glasses');
            _isSpeaking = false;
            onComplete?.call();
          },
          onError: (error) {
            debugPrint('‚ùå BLE transmission failed: $error');
            _isSpeaking = false;
            onError?.call('BLE transmission failed: $error');
          },
        );
      } else {
        debugPrint('‚ùå BLE not available - cannot transmit audio');
        _isSpeaking = false;
        onError?.call('BLE service not available');
      }
    } catch (e) {
      debugPrint('Error generating speech: $e');
      _isSpeaking = false;
      onError?.call(e.toString());
    }
  }

  /// Stop current speech transmission
  Future<void> stopSpeaking() async {
    _isSpeaking = false;
    debugPrint('Speech transmission stopped');
  }



  /// Get performance metrics of the TTS engine
  Map<String, dynamic> getEngineInfo() {
    if (_sherpaEngine == null) return {};
    
    return {
      'engine': 'Sherpa ONNX',
      'model': 'VITS-Piper en_US-libritts_r-medium',
      'type': 'Neural TTS',
      'offline': true,
      'speed': _speechSpeed,
      'transmission': canUseBle ? 'BLE (Smart Glasses) - 22050Hz' : 'BLE Unavailable',
      'sampleRate': '22050Hz (Original Quality)',
    };
  }

  /// Create and configure the Sherpa ONNX offline TTS engine
  Future<sherpa_onnx.OfflineTts> _createOfflineTts() async {
    // Copy all asset files to local storage (required by Sherpa ONNX)
    await _copyAllAssetFiles();

    // Configure for the vits-piper-en_US-libritts_r-medium model
    String modelDir = 'vits-piper-en_US-libritts_r-medium';
    String modelName = 'en_US-libritts_r-medium.onnx';
    String dataDir = 'vits-piper-en_US-libritts_r-medium/espeak-ng-data';

    final Directory directory = await getApplicationSupportDirectory();
    modelName = p.join(directory.path, modelDir, modelName);
    dataDir = p.join(directory.path, dataDir);
    final tokens = p.join(directory.path, modelDir, 'tokens.txt');

    final vits = sherpa_onnx.OfflineTtsVitsModelConfig(
      model: modelName,
      lexicon: '',
      tokens: tokens,
      dataDir: dataDir,
      dictDir: '',
    );

    final kokoro = sherpa_onnx.OfflineTtsKokoroModelConfig();

    final modelConfig = sherpa_onnx.OfflineTtsModelConfig(
      vits: vits,
      kokoro: kokoro,
      numThreads: 2,
      debug: true,
      provider: 'cpu',
    );

    final config = sherpa_onnx.OfflineTtsConfig(
      model: modelConfig,
      ruleFsts: '',
      ruleFars: '',
      maxNumSenetences: 1,
    );

    final tts = sherpa_onnx.OfflineTts(config);
    debugPrint('‚úÖ Sherpa ONNX TTS engine created successfully');

    return tts;
  }


  /// Get all asset files from the app bundle
  Future<List<String>> _getAllAssetFiles() async {
    final AssetManifest assetManifest =
        await AssetManifest.loadFromAssetBundle(rootBundle);
    final List<String> assets = assetManifest.listAssets();
    return assets;
  }

  /// Strip leading directory from path
  String _stripLeadingDirectory(String src, {int n = 1}) {
    return p.joinAll(p.split(src).sublist(n));
  }

  /// Copy all asset files to local storage
  Future<void> _copyAllAssetFiles() async {
    final allFiles = await _getAllAssetFiles();
    for (final src in allFiles) {
      final dst = _stripLeadingDirectory(src);
      await _copyAssetFile(src, dst);
    }
  }

  /// Copy an asset file from src to dst
  Future<String> _copyAssetFile(String src, [String? dst]) async {
    final Directory directory = await getApplicationSupportDirectory();
    if (dst == null) {
      dst = p.basename(src);
    }
    final target = p.join(directory.path, dst);
    bool exists = await File(target).exists();

    final data = await rootBundle.load(src);
    if (!exists || File(target).lengthSync() != data.lengthInBytes) {
      final List<int> bytes =
          data.buffer.asUint8List(data.offsetInBytes, data.lengthInBytes);
      await (await File(target).create(recursive: true)).writeAsBytes(bytes);
    }

    return target;
  }



  /// Convert Float32List audio samples to bytes for BLE transmission
  /// Creates a simple header with sample rate info + raw audio data
  Uint8List _convertSamplesToBytes(Float32List samples, int sampleRate) {
    // Create a simple header: [sampleRate(4 bytes)] + [numSamples(4 bytes)] + [audio data]
    final ByteData headerData = ByteData(8);
    headerData.setInt32(0, sampleRate, Endian.little);
    headerData.setInt32(4, samples.length, Endian.little);
    
    // Convert Float32 samples to 16-bit PCM for efficient transmission
    final pcmData = ByteData(samples.length * 2); // 2 bytes per sample (16-bit)
    
    for (int i = 0; i < samples.length; i++) {
      // Convert float (-1.0 to 1.0) to 16-bit signed integer (-32768 to 32767)
      int pcmValue = (samples[i] * 32767).round().clamp(-32768, 32767);
      pcmData.setInt16(i * 2, pcmValue, Endian.little);
    }
    
    // Combine header + audio data
    final totalBytes = Uint8List(8 + pcmData.lengthInBytes);
    totalBytes.setRange(0, 8, headerData.buffer.asUint8List());
    totalBytes.setRange(8, totalBytes.length, pcmData.buffer.asUint8List());
    
    final compressionRatio = ((totalBytes.length / (samples.length * 4)) * 100).toStringAsFixed(1);
    debugPrint('‚úÖ Raw audio converted to bytes:');
    debugPrint('   Original: ${samples.length} Float32 samples (${samples.length * 4} bytes)');
    debugPrint('   Converted: ${samples.length} 16-bit PCM samples (${totalBytes.length} bytes)');
    debugPrint('   Compression: ${compressionRatio}% of original size');
    debugPrint('   Format: Custom header + 16-bit PCM data');
    
    return totalBytes;
  }



  /// Dispose of resources
  Future<void> dispose() async {
    await stopSpeaking();
    _sherpaEngine?.free();
    _sherpaEngine = null;
    _isInitialized = false;
    debugPrint('Sherpa ONNX TTS service disposed');
  }
}